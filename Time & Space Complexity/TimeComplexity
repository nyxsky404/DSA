Time and Space Complexity

Time Complexity ?
Rate of increase in the running time of an algorithm as the input size increases

For example:
If a piece of code has a time complexity of O(n), it means the running time increases linearly with the size of the input.
If the input size doubles, the time taken roughly doubles.


Space Complexity ?
Rate of increase in the memory consumption of an algorithm as the input size increases.

This includes:
Input Space: Variables/ Memory needed for input storage.
Auxiliary Space: Any extra memory that grows with the size of the problem (like arrays, hash tables, recursion stacks, etc.).

If an algorithm uses a constant amount of space, regardless of input size, it has O(1) space complexity. If it requires space proportional to the input size, it has O(n) space complexity.


Types of Time and Space Complexity:
Based on the behavior of algorithms as input size increases:

Common Notations:
Big O (O): Describes the worst-case scenario. (upper bound)
Big Omega (Ω): Describes the best-case scenario.
Big Theta (Θ): Describes the average-case scenario.


Examples of common Big O complexities:
O(1): Constant Time
O(log n): Logarithmic Time
O(n): Linear Time
O(n log n): Linearithmic Time
O(n²): Quadratic Time
O(2ⁿ): Exponential Time


Rules to Calculate Time and Space Complexity
When calculating the complexity of any algorithm, some general rules are applied:

1. Focus on the Highest Growing Term
In an expression like O(n² + n), the dominant term (n²) is considered, so the overall complexity is O(n²).

2. Ignore Constant Multipliers
Expressions like O(3n) or O(100n) are simplified to O(n) because constants do not affect growth trends.

3. Consider the Worst Case
When multiple possibilities exist (like loops, conditionals, or recursion), the worst-case scenario determines the final time complexity.

4. Add or Multiply Based on Code Structure
Sequential operations are added.

Nested operations (like loops inside loops) are multiplied.


Finding the Time Complexity of "Nested for loops"
